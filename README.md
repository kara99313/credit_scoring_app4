# ğŸ’³ Credit Scoring System

Un systÃ¨me complet de credit scoring utilisant la rÃ©gression logistique avec des pipelines ML robustes et une interface utilisateur interactive.

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

## ğŸ“‹ Table des MatiÃ¨res

- [AperÃ§u du Projet](#aperÃ§u-du-projet)
- [Architecture](#architecture)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du Projet](#structure-du-projet)
- [Configuration](#configuration)
- [DÃ©veloppement](#dÃ©veloppement)
- [DÃ©ploiement](#dÃ©ploiement)
- [Documentation](#documentation)

## ğŸ¯ AperÃ§u du Projet

Le **Credit Scoring System** est une solution complÃ¨te de machine learning pour l'Ã©valuation du risque de crÃ©dit. Il comprend :

### ğŸ”§ **Partie 1 : Pipeline ML & API**
- **Pipeline de donnÃ©es** complet (ETL, nettoyage, validation)
- **Feature Engineering** avancÃ© avec techniques mÃ©tier
- **ModÃ¨le de rÃ©gression logistique** optimisÃ© avec hyperparamÃ¨tres
- **API REST FastAPI** pour scoring temps rÃ©el
- **MLOps** complet avec CI/CD, monitoring et versioning

### ğŸ–¥ï¸ **Partie 2 : Application Interactive**
- **Interface Streamlit** intuitive pour les utilisateurs mÃ©tier
- **Moteur de scoring** en temps rÃ©el
- **GÃ©nÃ©ration de rapports PDF** professionnels
- **Analytics avancÃ©s** : analyse de sensibilitÃ©, simulations

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    A[Raw Data] --> B[Data Pipeline]
    B --> C[Feature Engineering]
    C --> D[Model Training]
    D --> E[Model Registry]
    E --> F[API Service]
    E --> G[Streamlit App]
    F --> H[Predictions]
    G --> I[Reports & Analytics]
    
    subgraph "MLOps"
        J[MLflow Tracking]
        K[Model Monitoring]
        L[CI/CD Pipeline]
    end
    
    D --> J
    F --> K
    G --> K
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- Git
- 4GB RAM minimum
- Windows/macOS/Linux

### Installation Rapide

```bash
# 1. Cloner le repository
git clone <repository-url>
cd credit_scoring_project

# 2. CrÃ©er l'environnement virtuel
python -m venv credit_scoring_env

# 3. Activer l'environnement virtuel
# Windows
credit_scoring_env\Scripts\activate
# macOS/Linux
source credit_scoring_env/bin/activate

# 4. Installer les dÃ©pendances
pip install -r requirements.txt

# 5. VÃ©rifier l'installation
python main.py status
```

## ğŸ“Š Utilisation

### Commandes Principales

```bash
# Interface en ligne de commande
python main.py --help

# Pipeline complet (recommandÃ© pour commencer)
python main.py full-pipeline

# Ã‰tapes individuelles
python main.py process-data      # Traitement des donnÃ©es
python main.py train-model       # EntraÃ®nement du modÃ¨le
python main.py run-api          # DÃ©marrer l'API
python main.py run-app          # DÃ©marrer Streamlit
python main.py run-mlflow       # Interface MLflow

# PrÃ©dictions
python main.py predict --input-data data/new_clients.csv
```

### ğŸ”¥ DÃ©marrage Rapide

```bash
# 1. Traiter les donnÃ©es et entraÃ®ner le modÃ¨le
python main.py full-pipeline

# 2. Dans un nouveau terminal - DÃ©marrer l'API
python main.py run-api

# 3. Dans un autre terminal - DÃ©marrer l'app
python main.py run-app

# 4. AccÃ©der aux interfaces
# - API Docs: http://localhost:8000/docs
# - Streamlit: http://localhost:8501
# - MLflow: http://localhost:5000
```

## ğŸ“ Structure du Projet

```
credit_scoring_project/
â”œâ”€â”€ ğŸ“ config/                    # Configuration
â”‚   â”œâ”€â”€ config.yaml              # Configuration principale
â”‚   â””â”€â”€ logging_config.yaml      # Configuration logging
â”œâ”€â”€ ğŸ“ data/                     # DonnÃ©es
â”‚   â”œâ”€â”€ raw/                     # DonnÃ©es brutes
â”‚   â”œâ”€â”€ processed/               # DonnÃ©es traitÃ©es
â”‚   â””â”€â”€ external/                # DonnÃ©es externes
â”œâ”€â”€ ğŸ“ src/                      # Code source principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py       # Traitement des donnÃ©es
â”‚   â”œâ”€â”€ feature_engineering.py  # IngÃ©nierie des features
â”‚   â”œâ”€â”€ modeling.py             # ModÃ©lisation ML
â”‚   â”œâ”€â”€ backtesting.py          # Validation temporelle
â”‚   â””â”€â”€ utils.py                # Utilitaires
â”œâ”€â”€ ğŸ“ pipelines/               # Pipelines ML
â”‚   â”œâ”€â”€ data_pipeline.py        # Pipeline de donnÃ©es
â”‚   â”œâ”€â”€ training_pipeline.py    # Pipeline d'entraÃ®nement
â”‚   â”œâ”€â”€ inference_pipeline.py   # Pipeline d'infÃ©rence
â”‚   â””â”€â”€ monitoring_pipeline.py  # Pipeline de monitoring
â”œâ”€â”€ ğŸ“ api_service/             # Service API REST
â”‚   â”œâ”€â”€ app.py                  # Application FastAPI
â”‚   â”œâ”€â”€ endpoints/              # Points de terminaison
â”‚   â”œâ”€â”€ models/                 # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ schemas/                # SchÃ©mas de donnÃ©es
â”‚   â”œâ”€â”€ services/               # Services mÃ©tier
â”‚   â””â”€â”€ middleware/             # Middleware
â”œâ”€â”€ ğŸ“ streamlit_app/           # Application Streamlit
â”‚   â”œâ”€â”€ app.py                  # Application principale
â”‚   â”œâ”€â”€ pages/                  # Pages de l'app
â”‚   â”œâ”€â”€ components/             # Composants rÃ©utilisables
â”‚   â””â”€â”€ utils/                  # Utilitaires Streamlit
â”œâ”€â”€ ğŸ“ models/                  # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ ğŸ“ logs/                    # Logs systÃ¨me
â”œâ”€â”€ ğŸ“ notebooks/               # Notebooks Jupyter
â”œâ”€â”€ ğŸ“ tests/                   # Tests
â”œâ”€â”€ ğŸ“ deployment/              # Configuration dÃ©ploiement
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â””â”€â”€ Dockerfile.streamlit
â”œâ”€â”€ main.py                     # Point d'entrÃ©e principal
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â””â”€â”€ README.md                   # Documentation
```

## âš™ï¸ Configuration

### Configuration Principale (`config/config.yaml`)

```yaml
# Exemple de configuration
model:
  algorithm: "logistic_regression"
  hyperparameters:
    C: [0.001, 0.01, 0.1, 1, 10, 100]
    penalty: ["l1", "l2"]
    
scoring:
  score_range:
    min: 300
    max: 850
  risk_classes:
    very_low: [750, 850]
    low: [650, 749]
    medium: [550, 649]
    high: [450, 549]
    very_high: [300, 449]
```

### Variables d'Environnement

CrÃ©er un fichier `.env` :

```bash
# Base
ENVIRONMENT=development
LOG_LEVEL=INFO

# API
API_HOST=0.0.0.0
API_PORT=8000

# Database (optionnel)
DATABASE_URL=postgresql://user:pass@localhost/credit_scoring

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000
```

## ğŸ§ª DÃ©veloppement

### Tests

```bash
# ExÃ©cuter tous les tests
pytest

# Tests avec couverture
pytest --cov=src

# Tests spÃ©cifiques
pytest tests/test_data_processing.py
```

### QualitÃ© du Code

```bash
# Formatage du code
black src/

# Linting
flake8 src/

# Type checking
mypy src/
```

### Pre-commit Hooks

```bash
# Installer pre-commit
pip install pre-commit

# Configurer les hooks
pre-commit install

# ExÃ©cuter manuellement
pre-commit run --all-files
```

## ğŸš€ DÃ©ploiement

### Docker

```bash
# Construire les images
docker-compose build

# DÃ©marrer les services
docker-compose up -d

# VÃ©rifier le statut
docker-compose ps
```

### Kubernetes

```bash
# DÃ©ployer sur Kubernetes
kubectl apply -f deployment/

# VÃ©rifier le dÃ©ploiement
kubectl get pods -n credit-scoring
```

### Production

```bash
# Configuration production
export ENVIRONMENT=production

# DÃ©marrer avec Gunicorn
gunicorn api_service.app:app --workers 4 --worker-class uvicorn.workers.UvicornWorker
```

## ğŸ“š API Documentation

### Endpoints Principaux

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/predict` | POST | PrÃ©diction individuelle |
| `/batch-predict` | POST | PrÃ©diction en lot |
| `/model/info` | GET | Information sur le modÃ¨le |
| `/health` | GET | Statut de santÃ© |

### Exemple d'Utilisation

```python
import requests

# PrÃ©diction individuelle
response = requests.post(
    "http://localhost:8000/predict",
    json={
        "age": 35,
        "income": 50000,
        "debt_to_income": 0.3,
        "credit_history_length": 10
    }
)

result = response.json()
print(f"Score: {result['score']}")
print(f"Risk Class: {result['risk_class']}")
```

## ğŸ“ˆ Monitoring & ObservabilitÃ©

### MÃ©triques Disponibles

- **Performance du modÃ¨le** : AUC, PrÃ©cision, Rappel, F1-Score
- **DÃ©rive des donnÃ©es** : PSI, Distribution shifts
- **MÃ©triques systÃ¨me** : Latence, Throughput, Erreurs
- **MÃ©triques mÃ©tier** : Taux d'approbation, RentabilitÃ©

### Alertes

```yaml
# Configuration des alertes
alerts:
  model_performance:
    auc_threshold: 0.7
    precision_threshold: 0.6
  
  data_drift:
    psi_threshold: 0.1
    
  system:
    latency_threshold: 500ms
    error_rate_threshold: 0.05
```

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/amazing-feature`)
3. Commit les changements (`git commit -m 'Add amazing feature'`)
4. Push sur la branche (`git push origin feature/amazing-feature`)
5. Ouvrir une Pull Request

## ğŸ“ Changelog

### Version 1.0.0 (2024-12-XX)
- âœ¨ Pipeline ML complet avec rÃ©gression logistique
- ğŸš€ API REST FastAPI avec documentation automatique
- ğŸ“Š Application Streamlit interactive
- ğŸ”§ Configuration flexible et modulaire
- ğŸ“ˆ Monitoring et observabilitÃ©
- ğŸ³ Containerisation Docker
- ğŸ§ª Tests automatisÃ©s avec CI/CD

## ğŸ“„ License

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

Pour obtenir de l'aide :

1. ğŸ“– Consultez cette documentation
2. ğŸ› Ouvrez une [issue](issues) pour reporter un bug
3. ğŸ’¬ Rejoignez notre [Discord](discord-link) pour discuter
4. ğŸ“§ Contactez l'Ã©quipe : team@creditscore.com

---

**Fait avec â¤ï¸ par l'Ã©quipe Credit Scoring**

*SystÃ¨me de credit scoring professionnel pour l'industrie financiÃ¨re* 