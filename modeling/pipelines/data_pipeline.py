"""
Data Pipeline for Credit Scoring System

This module orchestrates the complete data processing pipeline.

Author: Credit Scoring Team
Created: 2024
"""

import sys
import pandas as pd
import logging
from pathlib import Path
from typing import Dict, Optional

# Add src to Python path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from src.data_processing import DataProcessor
from src.eda_analyzer import EDAAnalyzer
from src.transformers.feature_engineer import FeatureEngineer
from src.transformers.variable_transformer import VariableTransformer


class DataPipeline:
    """Pipeline de traitement des donnÃ©es complet"""
    
    def __init__(self, config: Dict):
        """
        Initialisation du pipeline de donnÃ©es
        
        Args:
            config: Configuration du projet
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def run(self, force_reprocess: bool = False):
        """
        ExÃ©cute le pipeline de donnÃ©es complet
        
        Args:
            force_reprocess: Force le retraitement mÃªme si les donnÃ©es existent
        """
        print("\nğŸ”„ PIPELINE DE DONNÃ‰ES COMPLET")
        print("=" * 50)
        
        # VÃ©rifier si les donnÃ©es finales existent dÃ©jÃ 
        final_data_path = Path("data/processed/credit_engineered_transformed.csv")
        if final_data_path.exists() and not force_reprocess:
            print("âœ… DonnÃ©es dÃ©jÃ  traitÃ©es trouvÃ©es. Utilisation des donnÃ©es existantes.")
            print(f"ğŸ“ Fichier: {final_data_path}")
            return
        
        # 1. Chargement et nettoyage des donnÃ©es
        print("\nğŸ“Š 1. Chargement et nettoyage des donnÃ©es...")
        processor = DataProcessor(self.config)
        df_cleaned = processor.load_and_clean_data()
        
        # 2. Analyse exploratoire (optionnel)
        if self.config.get('data_pipeline', {}).get('run_eda', False):
            print("\nğŸ“ˆ 2. Analyse exploratoire des donnÃ©es...")
            eda_analyzer = EDAAnalyzer(self.config)
            eda_analyzer.run_complete_analysis(df_cleaned)
        
        # 3. Feature Engineering
        print("\nğŸ”§ 3. Feature Engineering...")
        feature_engineer = FeatureEngineer(self.config)
        df_engineered = feature_engineer.engineer_all_features(df_cleaned)
        
        # 4. Transformation des variables
        print("\nâš™ï¸ 4. Transformation des variables...")
        transformer = VariableTransformer(self.config)
        
        # SÃ©paration des features et de la cible
        X = df_engineered.drop(columns=['cible'])
        y = df_engineered['cible']
        
        # Transformation complÃ¨te
        X_transformed = transformer.transform_all_variables(X, y, fit=True)
        
        # Reconstruction du DataFrame final
        df_final = X_transformed.copy()
        df_final['cible'] = y.values
        
        # 5. Sauvegarde
        print("\nğŸ’¾ 5. Sauvegarde des donnÃ©es transformÃ©es...")
        output_path = Path("data/processed")
        output_path.mkdir(exist_ok=True)
        
        # Sauvegarde du fichier final
        final_path = output_path / "credit_engineered_transformed.csv"
        df_final.to_csv(final_path, index=False)
        
        print(f"âœ… Pipeline de donnÃ©es terminÃ© avec succÃ¨s!")
        print(f"ğŸ“ DonnÃ©es sauvegardÃ©es: {final_path}")
        print(f"ğŸ“Š Shape finale: {df_final.shape}") 