# ğŸ“š DOCUMENTATION COMPLÃˆTE - PIPELINES & MODÃ‰LISATION

## ğŸ¯ SYSTÃˆME DE CREDIT SCORING - PHASE MODÃ‰LISATION

**Date de crÃ©ation :** 2024  
**Version :** 1.0  
**Auteur :** Credit Scoring Team  
**Phase :** MODÃ‰LISATION (Ã‰tape 2)

---

## ğŸ“‹ TABLE DES MATIÃˆRES

1. [ğŸ—ï¸ Architecture GÃ©nÃ©rale](#architecture-gÃ©nÃ©rale)
2. [ğŸ”„ Workflow Complet avec SchÃ©mas](#workflow-complet-avec-schÃ©mas)
3. [ğŸ“ Structure des Pipelines](#structure-des-pipelines)
4. [ğŸ” DÃ©tail des Pipelines](#dÃ©tail-des-pipelines)
5. [ğŸ“Š Flux de DonnÃ©es](#flux-de-donnÃ©es)
6. [ğŸš€ Applications](#applications)
7. [ğŸ”§ Commandes Utilisateur](#commandes-utilisateur)

---

## ğŸ—ï¸ ARCHITECTURE GÃ‰NÃ‰RALE

### ğŸ“Š Vue d'ensemble du systÃ¨me

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SYSTÃˆME CREDIT SCORING                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ DATA LAYER                                                 â”‚
â”‚  â”œâ”€â”€ raw/credit.csv (donnÃ©es brutes)                           â”‚
â”‚  â”œâ”€â”€ processed/credit_cleaned.csv (nettoyÃ©es)                  â”‚
â”‚  â”œâ”€â”€ processed/credit_engineered.csv (features)                â”‚
â”‚  â””â”€â”€ processed/credit_engineered_transformed.csv (finales)     â”‚
â”‚                                                                 â”‚
â”‚  ğŸ”„ PIPELINE LAYER                                              â”‚
â”‚  â”œâ”€â”€ data_pipeline.py (orchestrateur donnÃ©es)                  â”‚
â”‚  â”œâ”€â”€ training_pipeline.py (entraÃ®nement ML)                    â”‚
â”‚  â””â”€â”€ inference_pipeline.py (prÃ©dictions)                       â”‚
â”‚                                                                 â”‚
â”‚  ğŸ¤– MODEL LAYER                                                 â”‚
â”‚  â”œâ”€â”€ models/trained_model.pkl (modÃ¨le entraÃ®nÃ©)                â”‚
â”‚  â”œâ”€â”€ models/model_info.json (mÃ©tadonnÃ©es)                      â”‚
â”‚  â””â”€â”€ models/performance_metrics.json (mÃ©triques)               â”‚
â”‚                                                                 â”‚
â”‚  ğŸ–¥ï¸ APPLICATION LAYER                                           â”‚
â”‚  â”œâ”€â”€ Streamlit App (interface utilisateur)                     â”‚
â”‚  â”œâ”€â”€ FastAPI Service (API REST)                                â”‚
â”‚  â””â”€â”€ main.py (orchestrateur CLI)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ WORKFLOW COMPLET AVEC SCHÃ‰MAS

### ğŸ“ˆ Diagramme de flux principal

```mermaid
graph TD
    A["ğŸ“Š DonnÃ©es Brutes<br/>credit.csv"] --> B["ğŸ”„ Data Pipeline"]
    
    B --> B1["ğŸ§¹ Nettoyage"]
    B1 --> B2["ğŸ”§ Feature Engineering"]
    B2 --> B3["ğŸ”„ Transformation"]
    B3 --> C["ğŸ“ˆ DonnÃ©es Finales<br/>credit_engineered_transformed.csv"]
    
    C --> D["ğŸ¯ Training Pipeline"]
    D --> D1["ğŸ“Š Split Train/Test"]
    D1 --> D2["ğŸ” Hyperparameter Tuning"]
    D2 --> D3["ğŸ¤– EntraÃ®nement ModÃ¨le"]
    D3 --> E["ğŸ¯ ModÃ¨le EntraÃ®nÃ©<br/>trained_model.pkl"]
    
    E --> F["ğŸ”® Inference Pipeline"]
    E --> G["ğŸ“± Streamlit App"]
    E --> H["ğŸŒ FastAPI Service"]
    
    F --> I["ğŸ“Š PrÃ©dictions en Lot"]
    G --> J["ğŸ‘¤ Interface Utilisateur"]
    H --> K["ğŸ”Œ API REST"]
    
    style A fill:#ffcdd2
    style C fill:#c8e6c9
    style E fill:#fff3e0
    style G fill:#e1f5fe
    style H fill:#f3e5f5
```

### ğŸ“ Explication du flux :

1. **ğŸ“Š DonnÃ©es Brutes** â†’ **ğŸ”„ Data Pipeline** âœ… **TERMINÃ‰**
   - Chargement du fichier `credit.csv`
   - Passage par les 3 Ã©tapes de preprocessing

2. **ğŸ“ˆ DonnÃ©es Finales** â†’ **ğŸ¯ Training Pipeline** ğŸ¯ **EN COURS**
   - Split des donnÃ©es d'entraÃ®nement
   - Optimisation des hyperparamÃ¨tres
   - EntraÃ®nement du modÃ¨le final

3. **ğŸ¯ ModÃ¨le EntraÃ®nÃ©** â†’ **Applications** ğŸ”® **PROCHAINE Ã‰TAPE**
   - Utilisation dans l'interface Streamlit
   - DÃ©ploiement via API FastAPI
   - PrÃ©dictions en lot via Inference Pipeline

---

## ğŸ“ STRUCTURE DES PIPELINES

### ğŸ—ï¸ Organisation des fichiers

```
pipelines/
â”œâ”€â”€ __init__.py              # Package initializer
â”œâ”€â”€ data_pipeline.py         # ğŸ”„ Orchestrateur donnÃ©es âœ…
â”œâ”€â”€ training_pipeline.py     # ğŸ¯ Pipeline entraÃ®nement ML ğŸ¯
â””â”€â”€ inference_pipeline.py    # ğŸ”® Pipeline prÃ©dictions ğŸ”®
```

### ğŸ”— Interconnexions entre modules avec schÃ©ma

```mermaid
graph LR
    A[main.py] --> B[data_pipeline.py]
    A --> C[training_pipeline.py]
    A --> D[inference_pipeline.py]
    
    B --> E[src/data_processing.py]
    B --> F[src/transformers/]
    
    C --> G[sklearn models]
    C --> H[joblib serialization]
    
    D --> I[Streamlit App]
    D --> J[FastAPI Service]
    
    style A fill:#ff9800
    style B fill:#4caf50
    style C fill:#2196f3
    style D fill:#9c27b0
```

---

## ğŸ” DÃ‰TAIL DES PIPELINES

### ğŸ”„ 1. DATA_PIPELINE.PY - L'Orchestrateur âœ… TERMINÃ‰

**RÃ´le :** Chef d'orchestre du preprocessing des donnÃ©es

```python
# Workflow intelligent
def run(self, force_reprocess=False):
    1. âœ… VÃ©rification des donnÃ©es existantes
    2. ğŸ§¹ Nettoyage (si nÃ©cessaire)
    3. ğŸ”§ Feature Engineering (si nÃ©cessaire)
    4. ğŸ”„ Transformation (si nÃ©cessaire)
    5. ğŸ“Š GÃ©nÃ©ration rapport final
```

**Logique de dÃ©tection avec schÃ©ma :**

```mermaid
flowchart TD
    A[DÃ©marrage Data Pipeline] --> B{DonnÃ©es finales<br/>existent ?}
    
    B -->|OUI| C[âœ… Utilisation donnÃ©es existantes]
    B -->|NON| D[ğŸ”„ Traitement complet]
    
    C --> E[ğŸ“Š Affichage statistiques]
    
    D --> F[ğŸ§¹ Nettoyage]
    F --> G[ğŸ”§ Feature Engineering]
    G --> H[ğŸ”„ Transformation]
    H --> I[ğŸ’¾ Sauvegarde]
    I --> E
    
    style C fill:#4caf50
    style D fill:#ff9800
```

### ğŸ¯ 2. TRAINING_PIPELINE.PY - L'EntraÃ®neur ğŸ¯ EN COURS

**RÃ´le :** EntraÃ®nement et optimisation du modÃ¨le ML

```python
# Workflow d'entraÃ®nement
def run(self, auto_tune=True):
    1. ğŸ“Š Chargement donnÃ©es finales
    2. ğŸ”€ Split Train/Validation/Test (60/20/20)
    3. ğŸ” Optimisation hyperparamÃ¨tres (GridSearchCV)
    4. ğŸ¤– EntraÃ®nement modÃ¨le final
    5. ğŸ“ˆ Ã‰valuation performance (AUC-ROC, Accuracy, etc.)
    6. ğŸ’¾ Sauvegarde modÃ¨le + mÃ©tadonnÃ©es
```

**Processus d'optimisation avec schÃ©ma :**

```mermaid
flowchart TD
    A[ğŸ“Š DonnÃ©es Finales] --> B[ğŸ”€ Train/Val/Test Split]
    
    B --> C{Auto-tune<br/>activÃ© ?}
    
    C -->|OUI| D[ğŸ” GridSearchCV]
    C -->|NON| E[ğŸ¯ ParamÃ¨tres par dÃ©faut]
    
    D --> F[ğŸ¤– EntraÃ®nement Final]
    E --> F
    
    F --> G[ğŸ“ˆ Ã‰valuation]
    G --> H[ğŸ’¾ Sauvegarde]
    
    H --> I[ğŸ“Š Rapport Performance]
    
    style D fill:#ff9800
    style F fill:#4caf50
    style I fill:#2196f3
```

### ğŸ”® 3. INFERENCE_PIPELINE.PY - Le PrÃ©dicteur ğŸ”® PROCHAINE Ã‰TAPE

**RÃ´le :** PrÃ©dictions sur nouvelles donnÃ©es

```python
# Workflow de prÃ©diction
def predict(self, data):
    1. ğŸ“¥ Chargement modÃ¨le entraÃ®nÃ©
    2. ğŸ” Validation format donnÃ©es
    3. ğŸ”„ Preprocessing (identique au training)
    4. ğŸ¤– PrÃ©diction + probabilitÃ©s
    5. ğŸ“Š Post-processing des rÃ©sultats
    6. ğŸ“¤ Retour rÃ©sultats formatÃ©s
```

**Workflow de prÃ©diction avec schÃ©ma :**

```mermaid
graph TD
    A[Nouvelles DonnÃ©es] --> B[ğŸ” Validation Format]
    B --> C[ğŸ”„ Preprocessing]
    C --> D[ğŸ¤– ModÃ¨le EntraÃ®nÃ©]
    D --> E[ğŸ“Š PrÃ©dictions + ProbabilitÃ©s]
    E --> F[ğŸ“‹ Formatage RÃ©sultats]
    
    F --> G[ğŸ“± Streamlit UI]
    F --> H[ğŸŒ API Response]
    F --> I[ğŸ“Š Batch Results]
    
    style D fill:#4caf50
    style E fill:#fff3e0
```

---

## ğŸ“Š FLUX DE DONNÃ‰ES

### ğŸŒŠ Transformation des donnÃ©es Ã©tape par Ã©tape avec schÃ©ma

```mermaid
flowchart TD
    A[ğŸ“Š credit.csv<br/>1002 lignes Ã— 20 cols] --> B[ğŸ§¹ Nettoyage]
    
    B --> C[ğŸ“ˆ credit_cleaned.csv<br/>1000 lignes Ã— 20 cols<br/>- Suppression doublons<br/>- Traitement valeurs manquantes]
    
    C --> D[ğŸ”§ Feature Engineering]
    
    D --> E[ğŸ“Š credit_engineered.csv<br/>1000 lignes Ã— 25+ cols<br/>+ Variables d'interaction<br/>+ Ratios calculÃ©s]
    
    E --> F[ğŸ”„ Transformation]
    
    F --> G[âœ… credit_engineered_transformed.csv<br/>1000 lignes Ã— 16 cols<br/>- One-hot encoding<br/>- Standardisation<br/>- DonnÃ©es prÃªtes ML]
    
    style A fill:#ffcdd2
    style C fill:#fff3e0
    style E fill:#e8f5e8
    style G fill:#c8e6c9
```

### ğŸ“ˆ Tableau rÃ©capitulatif des transformations

| Ã‰tape | Fichier | Lignes | Colonnes | Transformations |
|-------|---------|--------|----------|-----------------|
| **1** | `credit.csv` | 1002 | 20 | ğŸ“Š **DonnÃ©es brutes** |
| **2** | `credit_cleaned.csv` | 1000 | 20 | ğŸ§¹ **Suppression doublons + valeurs manquantes** |
| **3** | `credit_engineered.csv` | 1000 | 25+ | ğŸ”§ **Features d'interaction + ratios** |
| **4** | `credit_engineered_transformed.csv` | 1000 | 16 | âœ… **One-hot encoding + standardisation** |

### ğŸ“ˆ Ã‰tat actuel de vos donnÃ©es

**DonnÃ©es finales prÃªtes :** `credit_engineered_transformed.csv`
- âœ… **1000 Ã©chantillons** (suppression de 2 doublons)
- âœ… **16 variables** (15 features + 1 cible)
- âœ… **Target Ã©quilibrÃ©e** : 700 (pas dÃ©faut) / 300 (dÃ©faut) = 70/30
- âœ… **Variables transformÃ©es** : Encodage et scaling appliquÃ©s
- âœ… **Features engineered** : Variables d'interaction crÃ©Ã©es

---

## ğŸš€ APPLICATIONS

### ğŸ“± 1. Interface Streamlit (`streamlit_app/`)

**Architecture avec schÃ©ma :**

```mermaid
graph TD
    A[ğŸ‘¤ Utilisateur] --> B[ğŸ“± Interface Streamlit]
    
    B --> C[ğŸ“Š Saisie DonnÃ©es Client]
    C --> D[ğŸ”® Inference Pipeline]
    D --> E[ğŸ¤– ModÃ¨le EntraÃ®nÃ©]
    E --> F[ğŸ“ˆ PrÃ©diction + ProbabilitÃ©]
    F --> G[ğŸ“Š Affichage RÃ©sultat]
    
    B --> H[ğŸ“ˆ Analyse EDA]
    B --> I[ğŸ“Š Visualisations]
    
    style B fill:#e1f5fe
    style F fill:#c8e6c9
```

**FonctionnalitÃ©s :**
- âœ… **Saisie interactive** des donnÃ©es client
- âœ… **PrÃ©diction en temps rÃ©el** avec probabilitÃ©s
- âœ… **Visualisations** des rÃ©sultats
- âœ… **Interface multilingue** (FR/EN/DE/ES)
- âœ… **Analyses EDA** intÃ©grÃ©es

### ğŸŒ 2. API FastAPI (`api_service/`)

**Architecture API avec schÃ©ma :**

```mermaid
graph TD
    A[ğŸ“± Client API] --> B[ğŸŒ FastAPI Endpoint]
    
    B --> C[ğŸ“Š Validation SchÃ©ma]
    C --> D[ğŸ”® Inference Pipeline]
    D --> E[ğŸ¤– ModÃ¨le EntraÃ®nÃ©]
    E --> F[ğŸ“ˆ PrÃ©diction JSON]
    F --> G[ğŸ“¤ RÃ©ponse API]
    
    style B fill:#f3e5f5
    style F fill:#c8e6c9
```

**Endpoints disponibles :**
- `POST /predict` : PrÃ©diction unique
- `POST /predict/batch` : PrÃ©dictions en lot
- `GET /model/info` : Informations du modÃ¨le
- `GET /health` : Statut du service

**Format API :**
```json
{
  "age": 35,
  "sexe": "masculin",
  "travail": "qualifie",
  "logement": "proprietaire",
  "epargne": "superieur a 1000",
  "compte_courant": "0 a 200",
  "duree_credit": 12,
  "objet": "voiture (occasion)",
  "montant": 5000
}
```

---

## ğŸ”§ COMMANDES UTILISATEUR

### ğŸ“‹ Interface CLI complÃ¨te (main.py)

```bash
# ğŸ”„ Traitement des donnÃ©es (si nÃ©cessaire)
python main.py process-data

# ğŸ¯ EntraÃ®nement du modÃ¨le avec optimisation
python main.py train-model --auto-tune

# ğŸ”® PrÃ©diction sur nouvelles donnÃ©es
python main.py predict --input data/new_clients.csv

# ğŸ“Š Analyses exploratoires
python main.py run-eda

# ğŸ“± Lancement interface Streamlit
python main.py run-streamlit

# ğŸŒ Lancement API FastAPI
python main.py run-api
```

### ğŸ¯ Workflow utilisateur pour la modÃ©lisation

**SÃ©quence recommandÃ©e avec schÃ©ma :**

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ Utilisateur
    participant M as ğŸ“‹ main.py
    participant D as ğŸ”„ DataPipeline
    participant T as ğŸ¯ TrainingPipeline
    participant I as ğŸ”® InferencePipeline
    participant A as ğŸ“± Application
    
    Note over U,A: Phase 1: DonnÃ©es âœ… TERMINÃ‰E
    
    Note over U,A: Phase 2: ModÃ©lisation ğŸ¯ EN COURS
    U->>M: python main.py train-model --auto-tune
    M->>T: EntraÃ®nement modÃ¨le
    T-->>M: âœ… ModÃ¨le entraÃ®nÃ©
    
    Note over U,A: Phase 3: DÃ©ploiement ğŸ”® PROCHAINE
    U->>M: python main.py run-streamlit
    M->>A: Lancement application
    A->>I: PrÃ©dictions utilisateur
    I-->>A: RÃ©sultats
```

1. **âœ… VÃ©rification des donnÃ©es** (dÃ©jÃ  fait)
2. **ğŸ¯ EntraÃ®nement du modÃ¨le** (Ã©tape actuelle) :
   ```bash
   python main.py train-model --auto-tune
   ```
3. **ğŸ“± Test de l'application** :
   ```bash
   python main.py run-streamlit
   ```
4. **ğŸŒ DÃ©ploiement API** :
   ```bash
   python main.py run-api
   ```

---

## ğŸ“Š Ã‰TAT ACTUEL DU PROJET - PHASE MODÃ‰LISATION

### âœ… **Ã‰TAPES COMPLÃ‰TÃ‰ES**

1. **ğŸ“Š Chargement & Validation** : âœ… FAIT
2. **ğŸ§¹ Nettoyage des DonnÃ©es** : âœ… FAIT
3. **ğŸ”§ Feature Engineering** : âœ… FAIT
4. **ğŸ”„ Transformation Variables** : âœ… FAIT
5. **ğŸ—ï¸ Infrastructure Pipelines** : âœ… FAIT

### ğŸ¯ **Ã‰TAPE ACTUELLE : MODÃ‰LISATION**

**ENTRAÃNEMENT DU MODÃˆLE** avec optimisation automatique :

```bash
python main.py train-model --auto-tune
```

Cette commande va :
1. âœ… DÃ©tecter automatiquement les donnÃ©es prÃªtes
2. ğŸ”€ CrÃ©er les splits Train/Validation/Test (60/20/20)
3. ğŸ” Optimiser les hyperparamÃ¨tres via GridSearchCV
4. ğŸ¤– EntraÃ®ner le modÃ¨le final sur toutes les donnÃ©es d'entraÃ®nement
5. ğŸ“ˆ Ã‰valuer les performances sur le set de test
6. ğŸ’¾ Sauvegarder le modÃ¨le et ses mÃ©tadonnÃ©es
7. ğŸ“Š GÃ©nÃ©rer un rapport de performance complet

### ğŸ”® **PROCHAINES Ã‰TAPES**

1. **ğŸ¯ Validation du modÃ¨le** : Analyse des mÃ©triques
2. **ğŸ“± Test interface utilisateur** : Streamlit
3. **ğŸŒ DÃ©ploiement API** : FastAPI
4. **ğŸ“Š Monitoring** : Suivi des performances

---

## ğŸ‰ AVANTAGES DE CETTE ARCHITECTURE

### ğŸš€ **EfficacitÃ©**
- **DÃ©tection intelligente** : Ã‰vite les recalculs inutiles
- **Traitement optimisÃ©** : Seulement si nÃ©cessaire
- **RÃ©utilisation** : DonnÃ©es transformÃ©es sauvegardÃ©es

### ğŸ”§ **ModularitÃ©**
- **Pipelines indÃ©pendants** : Chacun a un rÃ´le prÃ©cis
- **FacilitÃ© de maintenance** : Code organisÃ© et documentÃ©
- **ExtensibilitÃ©** : Ajout facile de nouvelles fonctionnalitÃ©s

### ğŸ“ˆ **ScalabilitÃ©**
- **Traitement par lots** : Gestion de gros volumes
- **API REST** : IntÃ©gration dans d'autres systÃ¨mes
- **DÃ©ploiement flexible** : Local ou cloud

### ğŸ‘¥ **ConvivialitÃ©**
- **Interface intuitive** : Streamlit multilingue
- **Commandes simples** : CLI avec options claires
- **Documentation complÃ¨te** : Guides d'utilisation

---

## ğŸ CONCLUSION - PHASE MODÃ‰LISATION

**Votre systÃ¨me de Credit Scoring est maintenant prÃªt pour l'entraÃ®nement !**

Toute l'infrastructure est en place :
- âœ… **DonnÃ©es transformÃ©es** et prÃªtes pour le ML
- âœ… **Pipelines crÃ©Ã©s** et opÃ©rationnels
- âœ… **Applications dÃ©veloppÃ©es** et configurÃ©es
- âœ… **Documentation complÃ¨te** avec schÃ©mas

**ğŸ¯ PHASE ACTUELLE : MODÃ‰LISATION**

**La prochaine commande lance l'entraÃ®nement avec optimisation automatique !** ğŸš€

```bash
python main.py train-model --auto-tune
```

Cette commande marquera le dÃ©but de la **Phase 2 : ModÃ©lisation** de votre projet de Credit Scoring ! 