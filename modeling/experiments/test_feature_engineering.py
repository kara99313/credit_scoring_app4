#!/usr/bin/env python3
"""
Script de test pour valider le pipeline de Feature Engineering et Transformation
Teste les Ã‰TAPES 3 et 4 selon les spÃ©cifications PROJET_COMPLET_SPECIFICATION.md

Author: Credit Scoring Team
Created: 2024
"""

import sys
import os
from pathlib import Path

# Ajout du dossier src au path
sys.path.append(str(Path(__file__).parent / "src"))

import pandas as pd
import numpy as np
from src.data_processing import DataProcessor
from src.transformers.feature_engineer import FeatureEngineer
from src.transformers.variable_transformer import VariableTransformer


def test_feature_engineering_pipeline():
    """
    Test complet du pipeline de Feature Engineering selon l'ordre des spÃ©cifications :
    Ã‰TAPE 1-2: Chargement et nettoyage (DataProcessor)
    Ã‰TAPE 3: Feature Engineering MÃ©tier (FeatureEngineer)
    Ã‰TAPE 4: Transformation Variables (VariableTransformer)
    """
    
    print("ğŸš€ TEST DU PIPELINE DE FEATURE ENGINEERING")
    print("=" * 60)
    
    # Ã‰TAPE 1-2: Chargement et nettoyage des donnÃ©es
    print("\nğŸ“Š Ã‰TAPE 1-2: CHARGEMENT ET NETTOYAGE DES DONNÃ‰ES")
    print("-" * 50)
    
    processor = DataProcessor()
    
    # Chargement des donnÃ©es
    data = processor.load_data("data/raw/credit.csv")
    if data is None:
        print("âŒ Erreur: Impossible de charger les donnÃ©es")
        return False
    
    # Nettoyage des donnÃ©es
    cleaned_data = processor.clean_data()
    if cleaned_data is None:
        print("âŒ Erreur: Impossible de nettoyer les donnÃ©es")
        return False
    
    print(f"âœ… DonnÃ©es chargÃ©es et nettoyÃ©es: {cleaned_data.shape}")
    
    # Ã‰TAPE 3: Feature Engineering MÃ©tier
    print("\nğŸ”§ Ã‰TAPE 3: FEATURE ENGINEERING MÃ‰TIER")
    print("-" * 40)
    
    engineer = FeatureEngineer()
    
    # Pipeline complet de feature engineering
    try:
        engineered_data = engineer.engineer_all_features(cleaned_data)
        
        # VÃ©rification des rÃ©sultats
        feature_info = engineer.get_feature_info()
        
        print(f"\nğŸ“ˆ RÃ©sultats Feature Engineering:")
        print(f"   â€¢ Features originales: {len(feature_info.get('original_features', []))}")
        print(f"   â€¢ Features business: {len(feature_info.get('business_features', []))}")
        print(f"   â€¢ Features interaction: {len(feature_info.get('interaction_features', []))}")
        print(f"   â€¢ Features temporelles: {len(feature_info.get('temporal_features', []))}")
        print(f"   â€¢ Total features: {feature_info.get('total_features', 0)}")
        
    except Exception as e:
        print(f"âŒ Erreur dans le Feature Engineering: {e}")
        return False
    
    # Ã‰TAPE 4: Transformation des Variables
    print("\nğŸ”„ Ã‰TAPE 4: TRANSFORMATION DES VARIABLES")
    print("-" * 45)
    
    transformer = VariableTransformer()
    
    # PrÃ©paration de la variable cible
    target = engineered_data['cible'] if 'cible' in engineered_data.columns else None
    features_data = engineered_data.drop(columns=['cible']) if 'cible' in engineered_data.columns else engineered_data
    
    try:
        # Ã‰TAPE 4.1 + 4.2: Encodage et Scaling (SANS sÃ©lection)
        print("\nğŸ”„ Phase 1: Encodage + Scaling (toutes les variables)")
        data_encoded = transformer.categorical_encoding(features_data, target, fit=True)
        data_encoded_scaled = transformer.numerical_scaling(data_encoded, fit=True)
        
        # Sauvegarde du fichier COMPLET transformÃ© (AVANT sÃ©lection)
        if target is not None:
            complete_data = data_encoded_scaled.copy()
            complete_data['cible'] = target.reset_index(drop=True)
        else:
            complete_data = data_encoded_scaled
            
        complete_output_path = "data/processed/credit_all_transformed.csv"
        complete_data.to_csv(complete_output_path, index=False)
        print(f"ğŸ’¾ Fichier COMPLET sauvegardÃ©: {complete_output_path}")
        print(f"   ğŸ“Š Forme: {complete_data.shape} ({complete_data.shape[1]-1} features + cible)")
        
        # Ã‰TAPE 4.3: SÃ©lection des features
        print("\nğŸ¯ Phase 2: SÃ©lection des meilleures features")
        transformed_data = transformer.feature_selection(data_encoded_scaled, target, fit=True)
        
        # VÃ©rification des rÃ©sultats
        transformation_info = transformer.get_transformation_info()
        
        print(f"\nğŸ“Š RÃ©sultats Transformation:")
        if 'categorical_encoding' in transformation_info:
            print(f"   â€¢ Variables catÃ©gorielles encodÃ©es: {len(transformation_info['categorical_encoding'])}")
        if 'numerical_scaling' in transformation_info:
            print(f"   â€¢ Variables numÃ©riques scalÃ©es: {len(transformation_info['numerical_scaling'].get('features_scaled', []))}")
        if 'feature_selection' in transformation_info:
            selection_info = transformation_info['feature_selection']
            print(f"   â€¢ Features sÃ©lectionnÃ©es: {selection_info.get('final_features', 0)}")
            print(f"   â€¢ RÃ©duction features: {transformation_info.get('feature_reduction', 0)}")
        
    except Exception as e:
        print(f"âŒ Erreur dans la Transformation: {e}")
        return False
    
    # RÃ‰SUMÃ‰ FINAL
    print("\nğŸ¯ RÃ‰SUMÃ‰ FINAL DU PIPELINE")
    print("=" * 35)
    print(f"âœ… DonnÃ©es initiales: {data.shape}")
    print(f"âœ… AprÃ¨s nettoyage: {cleaned_data.shape}")
    print(f"âœ… AprÃ¨s feature engineering: {engineered_data.shape}")
    print(f"âœ… AprÃ¨s encodage + scaling: {complete_data.shape}")
    print(f"âœ… AprÃ¨s sÃ©lection features: {transformed_data.shape}")
    
    # Sauvegarde des donnÃ©es finales (features sÃ©lectionnÃ©es)
    output_path = "data/processed/credit_engineered_transformed.csv"
    try:
        # Ajout de la cible si disponible
        if target is not None:
            final_data = transformed_data.copy()
            final_data['cible'] = target.reset_index(drop=True)
        else:
            final_data = transformed_data
            
        final_data.to_csv(output_path, index=False)
        print(f"ğŸ’¾ DonnÃ©es FINALES sauvegardÃ©es: {output_path}")
        print(f"   ğŸ“Š Forme: {final_data.shape} ({final_data.shape[1]-1} features sÃ©lectionnÃ©es)")
    except Exception as e:
        print(f"âš ï¸ Erreur sauvegarde: {e}")
    
    # RAPPORT DES FICHIERS GÃ‰NÃ‰RÃ‰S
    print(f"\nğŸ“‚ FICHIERS GÃ‰NÃ‰RÃ‰S:")
    print(f"   1. {complete_output_path}")
    print(f"      â†’ TOUTES les variables transformÃ©es ({complete_data.shape[1]-1} features)")
    print(f"   2. {output_path}")
    print(f"      â†’ Features sÃ©lectionnÃ©es optimisÃ©es ({final_data.shape[1]-1} features)")
    print(f"   ğŸ“‰ RÃ©duction: {complete_data.shape[1] - final_data.shape[1]} features supprimÃ©es")
    
    print("\nğŸ‰ PIPELINE DE FEATURE ENGINEERING TERMINÃ‰ AVEC SUCCÃˆS!")
    return True


def analyze_feature_importance():
    """
    Analyse rapide de l'importance des features crÃ©Ã©es
    """
    
    print("\nğŸ” ANALYSE DE L'IMPORTANCE DES FEATURES")
    print("=" * 50)
    
    try:
        # Chargement des donnÃ©es transformÃ©es
        data = pd.read_csv("data/processed/credit_engineered_transformed.csv")
        
        if 'cible' not in data.columns:
            print("âš ï¸ Variable cible non trouvÃ©e")
            return
        
        X = data.drop(columns=['cible'])
        y = data['cible']
        
        print(f"ğŸ“Š DonnÃ©es chargÃ©es: {X.shape}")
        
        # Analyse rapide avec Random Forest
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.model_selection import train_test_split
        
        # Division des donnÃ©es
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # EntraÃ®nement d'un modÃ¨le simple
        rf = RandomForestClassifier(n_estimators=100, random_state=42)
        rf.fit(X_train, y_train)
        
        # Importance des features
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': rf.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"\nğŸ† TOP 10 FEATURES LES PLUS IMPORTANTES:")
        print("-" * 40)
        for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):
            print(f"{i:2d}. {row['feature']:<30} {row['importance']:.4f}")
        
        # Score du modÃ¨le
        score = rf.score(X_test, y_test)
        print(f"\nğŸ“ˆ Score du modÃ¨le Random Forest: {score:.4f}")
        
    except Exception as e:
        print(f"âŒ Erreur dans l'analyse: {e}")


if __name__ == "__main__":
    """
    ExÃ©cution du test complet du pipeline de Feature Engineering
    """
    
    # Test du pipeline principal
    success = test_feature_engineering_pipeline()
    
    if success:
        # Analyse de l'importance des features
        analyze_feature_importance()
        
        print("\n" + "="*60)
        print("ğŸ¯ PROCHAINES Ã‰TAPES SELON LES SPÃ‰CIFICATIONS:")
        print("   â€¢ Ã‰TAPE 5: ModÃ©lisation OptimisÃ©e")
        print("   â€¢ Ã‰TAPE 6: Backtesting et Validation")
        print("   â€¢ PARTIE 2: Application Streamlit Interactive")
        print("="*60)
    else:
        print("\nâŒ Ã‰CHEC DU PIPELINE - VÃ©rifiez les erreurs ci-dessus")
        sys.exit(1) 